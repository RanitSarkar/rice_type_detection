{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tUdeLfwtqRa0yE69vjWhDLQmZ2BXDkyW",
      "authorship_tag": "ABX9TyPbixxCa26keRuSIr8fc8s1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RanitSarkar/rice_type_detection/blob/main/Rice_identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kasZ6gykFd0O",
        "outputId": "890aa420-164b-4e55-c3b0-2696b91e8dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/rice_image/rice_images.zip\""
      ],
      "metadata": {
        "id": "d_j5735KOiq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,GlobalAveragePooling2D\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "QQSDqAnOHmz7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=MobileNetV2(weights='imagenet', include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(512,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
        "x=Dense(512,activation='relu')(x) #dense layer 2\n",
        "preds=Dense(5,activation='softmax')(x) #final layer with softmax activation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfgKPCxLHm2s",
        "outputId": "8b5b9e52-41b3-4c23-f394-8cf95068ad8e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=preds)"
      ],
      "metadata": {
        "id": "PUJMdANXLkkH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8"
      ],
      "metadata": {
        "id": "H8XF43ZiLkmz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                 validation_split=0.3) #included in our dependencies"
      ],
      "metadata": {
        "id": "tcQk2AKyLkpa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory('/content/Rice_Image_Dataset',\n",
        "                                                    target_size=(224,224),\n",
        "                                                    color_mode='rgb',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    subset='training',\n",
        "                                                    shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU0H6uFGLkr7",
        "outputId": "784d5a92-cdb7-4cac-9961-0b8fa2b8e639"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 52500 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator = train_datagen.flow_from_directory('/content/Rice_Image_Dataset',\n",
        "                                                  target_size=(224,224),\n",
        "                                                  color_mode='rgb',\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  subset='validation',\n",
        "                                                  shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFttLwxrHm5s",
        "outputId": "2c609f91-d836-4fa5-d094-e40acc870097"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22500 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzwW56vFPhHU",
        "outputId": "9426d723-b59e-4576-e8a3-684f44a0dbe9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [ModelCheckpoint('model_chkpt/weights.{epoch:02d}_{val_loss:.4f}_{val_accuracy:.4f}.h5')]"
      ],
      "metadata": {
        "id": "KNU5jbtcPhJn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=train_generator,validation_data=val_generator,epochs=10,verbose=2,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "NyWYtFrIPhNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = keras.models.load_model('model_chkpt/weights.02_0.0039_0.9988.h5')"
      ],
      "metadata": {
        "id": "oT_jZKJeP8gt"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}